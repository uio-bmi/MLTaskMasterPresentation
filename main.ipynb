{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Machine learning in bioinformatics\n",
    "\n",
    "Dataset: a set of DNA sequences labeled with 0 and 1\n",
    "\n",
    "Aim: build a classifier that will predict the label for new DNA sequences\n",
    "\n",
    "ML workflow:\n",
    "\n",
    "- import the dataset\n",
    "- prepare ML method(s) and encoding(s) and the set of hyperparameters to be evaluated\n",
    "- set up the evaluation of methods and encodings\n",
    "- select the final model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the data\n",
    "\n",
    "The data is located in data.fa file. For each sequence, there is a line starting with `>` with the sequence label (0 or 1), and a new line with the DNA sequence itself:\n",
    "```\n",
    "> 1\n",
    "AGCGAGGCAGGTGCGGTCACGTGACCCGGCGGCGCTGCGGGGCAGCGGCCATTTTGCGGGGCGGCC\n",
    "> 0\n",
    "AGCGAGGGCGCTCGGAGTGCGACGTTTTGGCACCAGGCGGGGCGCACGGCATTGCCAAGCGGCCGC\n",
    "```\n",
    "\n",
    "Function load_data will import this data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGCGAGGCAGGTGCGGTCACGTGACCCGGCGGCGCTGCGGGGCAGC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AGCGAGGGCGCTCGGAGTGCGACGTTTTGGCACCAGGCGGGGCGCA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TCTGGTCCCACTTAGCGGGAGAAACTCGGGCCACGTGACTGTCTGA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TCGCGTCTCCTGCCTCCCTGTCCCGGGGCGAGGACTGTCTCAGAAA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACTCCCCAGGTCAGCTGACGCTGCGTCCTCAGCGGGCTGTCAAGTG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AGAAGAACTCGGGGCTGGAACCTGTCGTACGGGTGTCCAGCAGCTG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GCTGGGAGGCGGTCACGTGGCGCAGGATGCACCCAACACCACCGTC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GCCGCAGTCGGGCCCAGTGGATGGCGCACTCGACGGGAACCCGCGT...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TGAAGCCGCCATTTCCCCGGCCCAGCCACCACGTGACCCTTCTGCG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TCCCGGCGAGCACGGACATACCCCATAGCTTTCTCCTCCGCCCGTG...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  label\n",
       "0  AGCGAGGCAGGTGCGGTCACGTGACCCGGCGGCGCTGCGGGGCAGC...      1\n",
       "1  AGCGAGGGCGCTCGGAGTGCGACGTTTTGGCACCAGGCGGGGCGCA...      0\n",
       "2  TCTGGTCCCACTTAGCGGGAGAAACTCGGGCCACGTGACTGTCTGA...      1\n",
       "3  TCGCGTCTCCTGCCTCCCTGTCCCGGGGCGAGGACTGTCTCAGAAA...      0\n",
       "4  ACTCCCCAGGTCAGCTGACGCTGCGTCCTCAGCGGGCTGTCAAGTG...      1\n",
       "5  AGAAGAACTCGGGGCTGGAACCTGTCGTACGGGTGTCCAGCAGCTG...      0\n",
       "6  GCTGGGAGGCGGTCACGTGGCGCAGGATGCACCCAACACCACCGTC...      1\n",
       "7  GCCGCAGTCGGGCCCAGTGGATGGCGCACTCGACGGGAACCCGCGT...      0\n",
       "8  TGAAGCCGCCATTTCCCCGGCCCAGCCACCACGTGACCCTTCTGCG...      1\n",
       "9  TCCCGGCGAGCACGGACATACCCCATAGCTTTCTCCTCCGCCCGTG...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import load_data\n",
    "\n",
    "dataset = load_data(\"data.fa\")\n",
    "\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining ML methods and encodings\n",
    "\n",
    "In this section, a few ML methods will be defined. You can use any other suitable ML method from scikit-learn library that is already installed in this environment.\n",
    "\n",
    "One encoding is already defined and can be used right away. It represents a letter in a sequence as a vector of length 4 (4 possible letters: A, C, G, T) with one 1 and 0s elsewhere to indicate which letter is present at the given position. To represent the full sequence, these vectors are just concatenated one after another. For example, for sequence `AG` this representation looks like this:\n",
    "\n",
    "```\n",
    "[1, 0, 0, 0, 0, 0, 1, 0]\n",
    "```\n",
    "\n",
    "The first four digits describe letter A, the second four - letter G."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from util import encode_onehot\n",
    "\n",
    "\n",
    "# ML methods - defining ML methods to be used\n",
    "\n",
    "logistic_regression = LogisticRegression(penalty='l1', C=10, solver='saga', max_iter=500)\n",
    "random_forest = RandomForestClassifier()\n",
    "\n",
    "# encodings - encodes the data right away and returns a dictionary with encoded_data, labels, and feature_names\n",
    "\n",
    "one_hot_encoded_data = encode_onehot(dataset)\n",
    "\n",
    "print(one_hot_encoded_data['encoded_data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a custom encoding\n",
    "\n",
    "Another encoding that can be used in this setting is based on the frequency of subsequences within a sequence.\n",
    "\n",
    "For example, if the original sequence is `AGCGAG`, subsequences of length 3 (3-mers) are:\n",
    "- `AGC`\n",
    "- `GCG`\n",
    "- `CGA`\n",
    "- `GAG`.\n",
    "\n",
    "The encoding would then represent each sequence by the frequency of each possible 3-mer. For sequence `AGCGAG` it would be:\n",
    "\n",
    "```\n",
    "[0., 0., 0., 0., 0., 0., 0., 0., 0, 0.25, 0.,\n",
    " 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    " 0., 0., 0.25, 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    " 0., 0.25, 0., 0., 0., 0.25, 0., 0., 0., 0., 0.,\n",
    " 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    " 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "```\n",
    "\n",
    "The first number is then the frequency of 3-mer `AAA`, the second the frequency of `AAC`, third `AAG`, ..., and the last one is the frequency of `TTT`.\n",
    "\n",
    "Here you can implement the function that will encode the dataset by representing each DNA sequence by the frequency of its subsequences.\n",
    "\n",
    "The function should take a pandas DataFrame as input with columns `sequence` and `label` (as shown above). It should output a dictionary with the following keys: `encoded_data` (matrix where each row represents one sequence and each column represents the frequency of one k-mer), `labels` (an array of labels for each sequence), and `feature_names` (a list of features names, e.g., `AAA`, `AAC`, `ACA`, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'G', 'T']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from util import ALPHABET\n",
    "\n",
    "# all letters (nucleotides) that can be used in a sequence:\n",
    "print(ALPHABET)\n",
    "\n",
    "# define a custom encoding:\n",
    "\n",
    "def encode_kmer_frequencies(dataset: pd.DataFrame, k: int) -> dict:\n",
    "    \n",
    "    # add your code here and fill in the returned object\n",
    "    \n",
    "    return {\n",
    "        'encoded_data': None,\n",
    "        'labels': None,\n",
    "        'feature_names': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-mer encoding works!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from util import test_kmer_encoding\n",
    "\n",
    "test_kmer_encoding(encode_kmer_frequencies_func=encode_kmer_frequencies)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting optimal ML model and encoding\n",
    "\n",
    "To find the best ML model and encoding, we can use the defined models and encodings, train and assess their performance and select the best one using the procedure called cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assessing split: 1/3\n",
      "Assessing combination: encoding_1_ml_1\n",
      "Assessing combination: encoding_1_ml_2\n",
      "Assessing split: 2/3\n",
      "Assessing combination: encoding_1_ml_1\n",
      "Assessing combination: encoding_1_ml_2\n",
      "Assessing split: 3/3\n",
      "Assessing combination: encoding_1_ml_1\n",
      "Assessing combination: encoding_1_ml_2\n",
      "{'encoding_1_ml_1': [0.6086232728483436, 0.5897286499084402, 0.5703346096221076], 'encoding_1_ml_2': [0.5684201764607958, 0.5575994672881638, 0.5448643249542201]}\n",
      "\n",
      "Optimal combination is encoding_1_ml_1.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import copy\n",
    "from util import standardize\n",
    "\n",
    "encoded_datasets = [one_hot_encoded_data] # if implemented k-mer encoding, add k-mer encoded dataset to this list\n",
    "ml_models = [logistic_regression, random_forest] # add here all ML models to assess\n",
    "\n",
    "metric_func = accuracy_score\n",
    "n_splits = 3\n",
    "performances = {}\n",
    "\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "for split_index, (train_indices, test_indices) in enumerate(kf.split(range(dataset.shape[0]))):\n",
    "    \n",
    "    print(f\"Assessing split: {split_index+1}/{n_splits}\")\n",
    "\n",
    "    for i, encoded_dataset in enumerate(encoded_datasets):\n",
    "        \n",
    "        train_data = encoded_dataset['encoded_data'][train_indices]\n",
    "        train_labels = encoded_dataset['labels'][train_indices]\n",
    "        \n",
    "        test_data = encoded_dataset['encoded_data'][test_indices]\n",
    "        test_labels = encoded_dataset['labels'][test_indices]\n",
    "        \n",
    "        train_data, test_data = standardize(train_data, test_data)\n",
    "        \n",
    "        for j, ml_model in enumerate(ml_models):\n",
    "            \n",
    "            combination = f\"encoding_{i+1}_ml_{j+1}\"\n",
    "            print(f\"Assessing combination: {combination}\")\n",
    "            \n",
    "            ml_model = copy.deepcopy(ml_model)\n",
    "            ml_model.fit(X=train_data, y=train_labels)\n",
    "            \n",
    "            performance = metric_func(y_pred=ml_model.predict(test_data), y_true=test_labels)\n",
    "                        \n",
    "            if combination in performances:\n",
    "                performances[combination].append(performance)\n",
    "            else:\n",
    "                performances[combination] = [performance]\n",
    "                \n",
    "print(performances)\n",
    "\n",
    "optimal_combination = max(performances, key=lambda k: sum(performances[k])/n_splits)\n",
    "        \n",
    "print(f\"\\nOptimal combination is {optimal_combination}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit optimal model to the full dataset\n",
    "\n",
    "Running the following cell will retrain the model to the full dataset and make it ready to apply on the new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, max_iter=500, penalty='l1', solver='saga')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_method = copy.deepcopy(ml_models[int(optimal_combination.split(\"_ml_\")[1])-1])\n",
    "optimally_encoded_data = copy.deepcopy(encoded_datasets[int(optimal_combination.split(\"_\")[1])-1])\n",
    "\n",
    "optimal_method.fit(optimally_encoded_data['encoded_data'], optimally_encoded_data['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the optimal combination on a new dataset\n",
    "\n",
    "Import the new dataset, encode it, test the performance of the optimal model on the new data, and report the new score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_data.fa'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f9/06b542k50w975k3r6p9k3t280000gn/T/ipykernel_60128/3530355223.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_data.fa\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mencoded_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_onehot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# alternatively: encode_kmer_frequencies(test_dataset, k=k), depending what was chosen as the optimal encoding in the previous step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/MLTaskMasterPresentation/util.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\">\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_data.fa'"
     ]
    }
   ],
   "source": [
    "test_dataset = load_data(\"test_data.fa\")\n",
    "\n",
    "encoded_test_dataset = encode_onehot(test_dataset) \n",
    "# alternatively: encode_kmer_frequencies(test_dataset, k=k), depending what was chosen as the optimal encoding in the previous step\n",
    "\n",
    "test_predictions = optimal_method.predict(encoded_test_dataset)\n",
    "\n",
    "performance = metric_func(y_true=test_dataset['labels'], y_pred=test_predictions)\n",
    "print(f\"Performance on test dataset: {performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
